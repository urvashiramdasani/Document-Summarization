{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "awesome-text-summarization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwqWdF0uJZLCksLhTu9ptq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urvashiramdasani/Document-Summarization/blob/main/notebooks/awesome_text_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygtymp4Syyll"
      },
      "source": [
        "The aim of this notebook is to provide all possible references to learn Text Summarization. It has been developed after reviewing papers and online material. Feel free to suggest any changes if you think they will improve this notebook!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB9180mT1B_Z"
      },
      "source": [
        "## Basics of Text Summarization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsWh96zUxquX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGvuAw-McwHE"
      },
      "source": [
        "## Basics of Hidden Markov Models\n",
        "\n",
        "Hidden Markov Models (HMMs) are a class of probabilistic graphical model that allow us to predict a sequence of unknown (hidden) variables from a set of observed variables. We are constructing an inference model based on the assumptions of a Markov process. The Markov process assumption is simply that the “future is independent of the past given the present”.\n",
        "\n",
        "Generally, the term “states” are used to refer to the hidden states and “observations” are used to refer to the observed states. The hidden states are also referred to as latent states.\n",
        "\n",
        "Intution - We compute the joint probability of sequence of hidden states and determine the best possible sequence i.e. the sequence with the highest probability and choose that sequence as the best sequence of hidden states.\n",
        "\n",
        "1. Transition data — the probability of transitioning to a new state conditioned on a present state.\n",
        "2. Emission data — the probability of transitioning to an observed state conditioned on a hidden state.\n",
        "3. Initial state information — the initial probability of transitioning to a hidden state. This can also be looked at as the prior probability.\n",
        "\n",
        "See Also - Baum Welch Algorithm\n",
        "\n",
        "HMMs for POS Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRTbwuhtczKE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}